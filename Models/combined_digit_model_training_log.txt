(env) user1@celab3:~/digitstraining/PuzzlePro-Backend$ /home/user1/digitstraining/env/bin/python /home/user1/digitstraining/PuzzlePro-Backend/Combined_Digit_Recognition/combined_digit_model_creation.py
2024-02-15 10:27:35.054190: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-02-15 10:27:35.055517: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-02-15 10:27:35.077565: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-15 10:27:35.077598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-15 10:27:35.078220: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-15 10:27:35.083755: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-02-15 10:27:35.083995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 10:27:35.506012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Total classes detected: 10
Importing classes for training...
Class 0: 661 images imported.
Class 1: 742 images imported.
Class 2: 750 images imported.
Class 3: 605 images imported.
Class 4: 630 images imported.
Class 5: 592 images imported.
Class 6: 526 images imported.
Class 7: 688 images imported.
Class 8: 560 images imported.
Class 9: 565 images imported.
 
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 2s 0us/step
Dataset Splitting Complete.
Number of training images: Printed Digits - 5055, MNIST - 54077
Number of testing images: Printed Digits - 1264, MNIST - 9020
Data Combination Complete.
Training Log

-------------


Model Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 26, 26, 32)        320       
                                                                 
 conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     
                                                                 
 max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 12, 12, 64)        256       
 Normalization)                                                  
                                                                 
 conv2d_2 (Conv2D)           (None, 10, 10, 128)       73856     
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 4, 4, 128)         0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 4, 4, 128)         512       
 chNormalization)                                                
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 dense (Dense)               (None, 512)               1049088   
                                                                 
 dense_1 (Dense)             (None, 19)                9747      
                                                                 
=================================================================
Total params: 1299859 (4.96 MB)
Trainable params: 1299475 (4.96 MB)
Non-trainable params: 384 (1.50 KB)
_________________________________________________________________
Epoch 1/100
1182/1182 [==============================] - 32s 26ms/step - loss: 0.3438 - accuracy: 0.8827 - val_loss: 0.3140 - val_accuracy: 0.8816 - lr: 0.0010
Epoch 2/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.2378 - accuracy: 0.9144 - val_loss: 0.2450 - val_accuracy: 0.9088 - lr: 0.0010
Epoch 3/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.1900 - accuracy: 0.9324 - val_loss: 0.1973 - val_accuracy: 0.9300 - lr: 0.0010
Epoch 4/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.1439 - accuracy: 0.9508 - val_loss: 0.1183 - val_accuracy: 0.9583 - lr: 0.0010
Epoch 5/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0680 - val_accuracy: 0.9785 - lr: 0.0010
Epoch 6/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 0.0589 - val_accuracy: 0.9830 - lr: 0.0010
Epoch 7/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.0365 - val_accuracy: 0.9901 - lr: 0.0010
Epoch 8/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0515 - accuracy: 0.9846 - val_loss: 0.0409 - val_accuracy: 0.9869 - lr: 0.0010
Epoch 9/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.0329 - val_accuracy: 0.9910 - lr: 0.0010
Epoch 10/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.0313 - val_accuracy: 0.9904 - lr: 0.0010
Epoch 11/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0337 - val_accuracy: 0.9902 - lr: 0.0010
Epoch 12/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.0705 - val_accuracy: 0.9795 - lr: 0.0010
Epoch 13/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.0356 - val_accuracy: 0.9893 - lr: 0.0010
Epoch 14/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.0252 - val_accuracy: 0.9919 - lr: 0.0010
Epoch 15/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.0211 - val_accuracy: 0.9932 - lr: 0.0010
Epoch 16/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0305 - val_accuracy: 0.9929 - lr: 0.0010
Epoch 17/100
1182/1182 [==============================] - 29s 25ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0297 - val_accuracy: 0.9913 - lr: 0.0010
Epoch 18/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0224 - val_accuracy: 0.9931 - lr: 0.0010
Epoch 19/100
1182/1182 [==============================] - 30s 25ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0266 - val_accuracy: 0.9931 - lr: 0.0010
Epoch 20/100
1182/1182 [==============================] - 30s 25ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 0.0242 - val_accuracy: 0.9934 - lr: 0.0010
Epoch 21/100
1182/1182 [==============================] - 30s 25ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0226 - val_accuracy: 0.9932 - lr: 0.0010
Epoch 22/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0247 - val_accuracy: 0.9921 - lr: 0.0010
Epoch 23/100
1182/1182 [==============================] - 30s 25ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0281 - val_accuracy: 0.9925 - lr: 0.0010
Epoch 24/100
1182/1182 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9924      
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0189 - val_accuracy: 0.9947 - lr: 0.0010
Epoch 25/100
1182/1182 [==============================] - 30s 25ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0174 - val_accuracy: 0.9949 - lr: 5.0000e-04
Epoch 26/100
1182/1182 [==============================] - 30s 26ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0151 - val_accuracy: 0.9956 - lr: 5.0000e-04
Epoch 27/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0181 - val_accuracy: 0.9947 - lr: 5.0000e-04
Epoch 28/100
1182/1182 [==============================] - 31s 26ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0182 - val_accuracy: 0.9947 - lr: 5.0000e-04
Epoch 29/100
1182/1182 [==============================] - 27s 22ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0163 - val_accuracy: 0.9952 - lr: 5.0000e-04
Epoch 30/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0139 - val_accuracy: 0.9964 - lr: 5.0000e-04
Epoch 31/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0186 - val_accuracy: 0.9956 - lr: 5.0000e-04
Epoch 32/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0154 - val_accuracy: 0.9950 - lr: 5.0000e-04
Epoch 33/100
1181/1182 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9969 
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0198 - val_accuracy: 0.9949 - lr: 5.0000e-04
Epoch 34/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0159 - val_accuracy: 0.9955 - lr: 2.5000e-04
Epoch 35/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0167 - val_accuracy: 0.9954 - lr: 2.5000e-04
Epoch 36/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0183 - val_accuracy: 0.9950 - lr: 2.5000e-04
Epoch 37/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0170 - val_accuracy: 0.9954 - lr: 2.5000e-04
Epoch 38/100
1180/1182 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978     
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0164 - val_accuracy: 0.9962 - lr: 2.5000e-04
Epoch 39/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0164 - val_accuracy: 0.9958 - lr: 1.2500e-04
Epoch 40/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0149 - val_accuracy: 0.9960 - lr: 1.2500e-04
Epoch 41/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0151 - val_accuracy: 0.9964 - lr: 1.2500e-04
Epoch 42/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0146 - val_accuracy: 0.9962 - lr: 1.2500e-04
Epoch 43/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0169 - val_accuracy: 0.9961 - lr: 1.2500e-04
Epoch 44/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0172 - val_accuracy: 0.9963 - lr: 1.2500e-04
Epoch 45/100
1182/1182 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987     
Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0155 - val_accuracy: 0.9963 - lr: 1.2500e-04
Epoch 46/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0154 - val_accuracy: 0.9966 - lr: 6.2500e-05
Epoch 47/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0158 - val_accuracy: 0.9963 - lr: 6.2500e-05
Epoch 48/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0157 - val_accuracy: 0.9966 - lr: 6.2500e-05
Epoch 49/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0153 - val_accuracy: 0.9966 - lr: 6.2500e-05
Epoch 50/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0153 - val_accuracy: 0.9963 - lr: 6.2500e-05
Epoch 51/100
1182/1182 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990     
Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0165 - val_accuracy: 0.9964 - lr: 6.2500e-05
Epoch 52/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0156 - val_accuracy: 0.9967 - lr: 3.1250e-05
Epoch 53/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0157 - val_accuracy: 0.9965 - lr: 3.1250e-05
Epoch 54/100
1182/1182 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991     
Epoch 54: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0152 - val_accuracy: 0.9965 - lr: 3.1250e-05
Epoch 55/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0152 - val_accuracy: 0.9966 - lr: 1.5625e-05
Epoch 56/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0153 - val_accuracy: 0.9966 - lr: 1.5625e-05
Epoch 57/100
1182/1182 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991 
Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-05.
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0154 - val_accuracy: 0.9967 - lr: 1.5625e-05
Epoch 58/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0152 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 59/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0153 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 60/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0152 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 61/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0153 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 62/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0151 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 63/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0150 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 64/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0148 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 65/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0152 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 66/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0148 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 67/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0150 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 68/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0151 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 69/100
1182/1182 [==============================] - 27s 23ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0150 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 70/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0151 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 71/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0152 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 72/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0154 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 73/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0154 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 74/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 75/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 76/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 77/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0157 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 78/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0159 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 79/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0159 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 80/100
1182/1182 [==============================] - 25s 22ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0157 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 81/100
1182/1182 [==============================] - 25s 22ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0158 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 82/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0160 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 83/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0160 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 84/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0157 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 85/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 86/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0156 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 87/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0157 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 88/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0159 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 89/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0160 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 90/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0160 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 91/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0159 - val_accuracy: 0.9968 - lr: 1.0000e-05
Epoch 92/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0158 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 93/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0159 - val_accuracy: 0.9967 - lr: 1.0000e-05
Epoch 94/100
1182/1182 [==============================] - 27s 23ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0160 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 95/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0161 - val_accuracy: 0.9966 - lr: 1.0000e-05
Epoch 96/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0161 - val_accuracy: 0.9964 - lr: 1.0000e-05
Epoch 97/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0158 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 98/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9965 - lr: 1.0000e-05
Epoch 99/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0164 - val_accuracy: 0.9964 - lr: 1.0000e-05
Epoch 100/100
1182/1182 [==============================] - 26s 22ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0163 - val_accuracy: 0.9965 - lr: 1.0000e-05
---Training time 2731.128494501114 seconds ---


Additional Details:
Batch Size: 50
Epochs: 100
Input Shape: (28, 28, 1)
Number of Classes: 19
Model saved at: 
322/322 [==============================] - 2s 5ms/step
---Testing time 1.7693963050842285 seconds ---
Test loss: 0.016298120841383934
Test accuracy: 0.9964994192123413
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       111
           1       1.00      1.00      1.00      1276
           2       0.99      1.00      1.00      1186
           3       0.99      1.00      1.00      1138
           4       0.99      1.00      1.00      1120
           5       1.00      1.00      1.00      1016
           6       1.00      1.00      1.00      1054
           7       1.00      0.99      1.00      1160
           8       1.00      1.00      1.00      1089
           9       1.00      0.99      0.99      1134

    accuracy                           1.00     10284
   macro avg       1.00      1.00      1.00     10284
weighted avg       1.00      1.00      1.00     10284

(env) user1@celab3:~/digitstraining/PuzzlePro-Backend$ ^C
(env) user1@celab3:~/digitstraining/PuzzlePro-Backend$ 